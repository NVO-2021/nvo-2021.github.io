<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常用命令大乱炖]]></title>
    <url>%2F2018%2F11%2F08%2F%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E4%B9%B1%E7%82%96%2F</url>
    <content type="text"><![CDATA[命令行这个东西，就像考试一样，书到用时方恨少。所以，平时积累一些常用的命令行和脚本zookeeper命令zkCli命令1zkCli -timeout 5000 -server 127.0.0.1:2181zkServer命令1234567891011121314$ zkServer JMX enabled by defaultUsing config: /usr/local/etc/zookeeper/zoo.cfgUsage: ./zkServer.sh &#123;start|start-foreground|stop|restart|status|upgrade|print-cmd&#125;$ zkServer statusJMX enabled by defaultUsing config: /usr/local/etc/zookeeper/zoo.cfgError contacting service. It is probably not running.$ zkServer startJMX enabled by defaultUsing config: /usr/local/etc/zookeeper/zoo.cfgStarting zookeeper ... STARTED]]></content>
      <tags>
        <tag>shell</tag>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql萌新入门指南]]></title>
    <url>%2F2018%2F11%2F04%2Fmysql%E8%90%8C%E6%96%B0%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[这里是萌新入门指南，瓢羹同学戳这里&gt;&gt;&gt;-- 插入 INSERT INTO `test-db`.`tb_student` ( `student_name`, `student_no`, `studnet_gender`, `favorite_course` ) VALUES ( 'tomb', 'no.11', '女', '1' ); -- 修改 update `test-db`.`tb_student` set `favorite_course` = '2',`student_name` = 'tombb' where `student_name` like '%b%'; -- 查询 select * from `test-db`.`tb_student` WHERE `student_no` = 'no.11'; select * from `test-db`.`tb_student` WHERE `student_name` = 'tombb'; -- 查询排序 -- asc: ascend的缩写，表示升序 select * from `test-db`.`tb_student` where `studnet_gender` = '男' order by `student_no` asc; -- desc: 表示降序 -- 字符默认按照从左往右的ascii顺序进行排序的 select * from `test-db`.tb_student where `studnet_gender` = '女' order by `student_no` desc; -- 删除 delete from `test-db`.`tb_student` where `student_name` = 'tombb'; -- 找出所有姓张的学生名字 select `student_name` as '学生姓名' from `test-db`.`tb_student` where `student_name` like '张%'; -- 联表查询 学生名称-&gt;课程名称 -- 注意：1.联表查询时，查询连接关键字为 “on”，单表查询连接关键字为 “where”。 -- 2.联表查询时，on后面可以再接where关键字，进行外表的进一步查询 select ts.`student_name`,tc.`course_name` from `tb_student` as ts inner join `tb_course` tc on ts.`favorite_course` = tc.`id`; -- 联表查询 学生名称-&gt;性别（男）-&gt;课程名称,查询条件并列的情况用 or，串联条件用 and。 -- 第一种：条件全写在on 之后的语句中 SELECT ts.`student_name` as '姓名', ts.`studnet_gender` as '性别', tc.`course_name` as '课程名称' FROM tb_student AS ts INNER JOIN `tb_course` tc ON ts.`favorite_course` = tc.`id` and ts.`studnet_gender` = '男'; -- 第二种，where 和 on 一起用,推荐用这种，因为事先先把主表符合要求的结果筛选出来，再与附表匹配，性能更好！ SELECT ts.`student_name` as '姓名', ts.`studnet_gender` as '性别', tc.`course_name` as '课程名称' FROM `tb_student` AS ts INNER JOIN `tb_course` tc ON ts.`favorite_course` = tc.`id` where ts.`studnet_gender` = '男'; -- 统计所有课程被学生喜欢的数量: 课程名称 -&gt; 数量 select tc.`course_name` as '课程名称', count(ts.`id`) as '数量' from `tb_course` as tc LEFT JOIN `tb_student` as ts on tc.`id` = ts.`favorite_course` GROUP BY tc.`id`; -- 这个例子有点难，所以我们先来安利一下 group by -- 根据性别统计学生数量 select `studnet_gender` as '性别', count(`studnet_gender`) as '数量' from `tb_student` GROUP BY `studnet_gender`; select sum( case when `studnet_gender` = '男' then 1 else 0 end ) as '男生数量', sum(case when `studnet_gender` = '女' then 1 else 0 end ) as '女生数量' from `tb_student` ;]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
        <tag>指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[周末遐思]]></title>
    <url>%2F2018%2F10%2F29%2F%E5%91%A8%E6%9C%AB%E9%81%90%E6%80%9D%2F</url>
    <content type="text"><![CDATA[function doDecrypt (pwd, onError) { console.log('in doDecrypt'); const txt = document.getElementById('enc_content').innerHTML; let plantext; try { const bytes = CryptoJS.AES.decrypt(txt, pwd); var plaintext = bytes.toString(CryptoJS.enc.Utf8); } catch(err) { if(onError) { onError(err); } return; } document.getElementById('enc_content').innerHTML = plaintext; document.getElementById('enc_content').style.display = 'block'; document.getElementById('enc_passwd').style.display = 'none'; if(typeof MathJax !== 'undefined') { MathJax.Hub.Queue( ['resetEquationNumbers', MathJax.InputJax.TeX], ['PreProcess', MathJax.Hub], ['Reprocess', MathJax.Hub] ); } } U2FsdGVkX1+c1DJLbP3tPImbzPCflkR5pdRo1mFE+ajx6j/rYwJ6uEtM6dtshl+KL4eClf4d3RWvjMLNeEzua2sT+OZOnG2CgNPfGPpQypN4ewqHbTOCBdtvb7ueZleX9GEFEeo+dfdPaAan+jr12KDzLBSR5EodQzoG7Non6x4z+2OT6yIXre46B58/z6NpV3nziyfbD7m9KifOyDH7ENXPxNPrpgW1hr692fzKRVWx5XTttr5Z9NXSOjLsQewRf1rvY/2Ztuem+QByOB1Pp4vM3qeBmOGCJ6b9mQBMj508cZZGV/HIPItQhfh2NU8lAY0BKs2Rh15OKWqJJVhf6Bgdp2S4sV3ix2Zaip7xd2APiTI65gY5WbPyOvdVSF1lV5FT4Oc8N1BsEc9rQkwL2fHFb+HTCxxD8inAWoFlrJMRT8lHz1zo3gP8P7UdK4AqXwk7AocVLAV+ZutVzcmwwcdyuWZpCTx1yi5itxGgPhbhlwXwzSfC9TiEIJBKSGNA7QOJErAC09a4w+gcRDoglCj25/9eGT0gMvQoqhckC6lrLel8Pw+wKnBJ7Rz/biF2KdK6RNulFSiBHZxvFNPq/9zvonHfEaWZsGfJFVXi3zTnKwZKjx+nVbxDsQikXBeclNo/ajuzthg1cabvwQSG37r56WlbnfW19eXctLG6h47k73zo6Cg9TofxNuOHbLerjLJ0Zcb8+9iVLmVKSShih+NuPh8uuXvJowDIY/p+ZeigSPs34AA+lHOA7alAeY0P/E7NJETJ6xiUavRYQ997nTVgESM1hE0WAR5HiUY0wHyg+CNabvJo+TfNAIdj3FpYdsdWPfAEtxP+BTU1HQDtz/KwlP9t5xbA+OkU3x6nAtIF491UXjIrlLVS4wSn1F37IOoF41J8Dqu26x1guu0rw8jyCJLh5ITO5TZEGWUfjDQwyxnw8He5l1G74Revyx4cdaBvB2RRf0ghnyLfvDElISlOwMnldqYeUgon9KKKqBlcIFw3HWlxwc/UBa/aQpoMNmplzfhEnnLa6akWJ5VSSqBrBP2cE5cN258iUXZDs0pK197r3a8s+nQ+UvLUXygvL7YW145jJWeNlbzSxbhaOYuXqIn1yCXay41kN92Crg5tjJuA32GrLmL1aDLpCwPn29CG5M40y6ef5ZAtG4JlL3XlaeWP7ii8rhtkSLuA/glSRgRkMtmJNXCCeXQ1h5iZhdCBlTzYtE7TRVxavoidrHlBtfGAw7H+NZSH5ce8Y/OqGlOWiovbfH/aRGOUmwZikCJaXUlCyo8dZTXON7fQs/YXL8PXB+ZC8HvPjl/Kfz4KfYgDVmAx7NrpnwZg8f+f6D3R4x/manKnk3qcAigoj+PPl/CgMvFxRIe0FdUpMSgRm1KM+JRwXRPP4bhNKUvyZF/EP+TwRor6hRD01GMHwUBMpWCFZwdcRo3/6EyGWG2x6CxUfHCss9OJb8PaE2Nk6jna+hHz8veWAOmZXvVrd9PL203sEO67omJGyNWbvR00CnyT7irbgcEZbODKIm+tdPyjDAtNtMDPb/B5mtdhcKLsEJymbYKk0EntYY5W93W3NQ3g5lg7AgUkG3OR24bQmdtth75if8PxuIYFeLeSvpSgYkpK8xxwjTFooEOMZ07e7dS6jm+x9G3U88efzciAm1Apg3KrePOjFduTYNWdYKYdpcrVmsq0sPfSo0X0Cf60GPdQSbwzVhqhzLPuaKXMHIZBSUuYSlgBQyD8G7C5uu21fRl9qZQ3pyOrB/l4aNEITUT9wOAk38piNlFnZau/FboLZ7cX4wv/llMpRVRoDXWAUwDkumAXNkhdvIGH9LMkjPM6eH/TXUZeq7wJ4RKCOmbAQC5DUfJbz+TWRi/82nkHb2dqWWcyE94aMkgdVf0OTrV4m9bALd+asrBwau+ja3Fhy5YedB/2fC+ZvHguTfTiPmMbdeC0PdPeh5tgcFGqF5Bta+JuDFT24S/7WCxL8WD0baRaARK3vvcQpRBHcgeAKWcgtRYlBB8zP0SDZRXMxLNSbOZhg2qTx3CR9OUrCMD1jBeWbE9nnixbxAE8pBFi+DFeajZJjVY/1CydccaiHZsb6aFISLhpGBG7Wt/n0jdkNR2lkA7Un50njy8ZHm4iu4UIp1OHNhyl136T+5tHq1Mt8vI0DFIWxIEYp7oQa2kcXU4zQKVKtW+0rkBEhJLl7541LvG88bw2BO4xN7dqNQdq6/GRS3IxCn2jB4PHbPq5V5D1nZ/xC+B/YzL9uoEqx+12DIcXbjfIF5vB6Jmpeq8aRUTClG4Y15MX9PAX98Mom/RMgu0tiPqctx5m59era//pnH8Ciw68ws4QXmiSvFBPuy2rwA4WeNJdSWQzclgYUQfTfZbtlaXlkQ9CIKk2Vb4NlT03gJex9PYFpBjppSemCVFi3UsVL4qlrsdlnDxwfS8LpgzdFOwdFSEVDEjWT1a77n+RjA+URBCysczIEMUckmhCPyA7sAJLoGVOetkcCL4J2gvqmSoPWjnQclk8PUbX31UxwXW699TWUo3HywBoCWQJNwSudpQUEA7Behu2jW9/JVEz/alNqPDtEYTR7IS94Ij+tBPMuwz22+iTH73JsJ/CzCre5T0i4h0Tq1ZLP+77YJ9sdkpTXIRIWN8SeJ4bgkMf+xknNz3BvO1+4g9EU67MHbiy38ZIH3m9uwboBw6kbFzALcgzetZia53isuGaY5ttAarFvHzaYKblkXDDT+DEtzuXQZrXUK+VqwZkltH50suf4P85MPFSKw0sj7F8QnpUGxoWUJf9VDbboRHjrZXZ2y+f0w/atfRp var onError = function(error) { document.getElementById("enc_error").innerHTML = "password error!" }; function decrypt() { var passwd = document.getElementById("enc_pwd_input").value; console.log(passwd); doDecrypt(passwd, onError); }]]></content>
      <tags>
        <tag>脑洞</tag>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那些令人捧腹的梗]]></title>
    <url>%2F2018%2F10%2F26%2F%E9%82%A3%E4%BA%9B%E4%BB%A4%E4%BA%BA%E6%8D%A7%E8%85%B9%E7%9A%84%E6%A2%97%2F</url>
    <content type="text"><![CDATA[关于程序员的老梗金庸小说人物英文名，你能猜对几个]]></content>
      <tags>
        <tag>脑洞</tag>
        <tag>搞笑</tag>
        <tag>梗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elastic-job源码浅析-源码分析]]></title>
    <url>%2F2018%2F10%2F25%2Felastic-job%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[核心源码分析核心入口：JobScheduler作业调度器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 作业调度器. * * @author zhangliang * @author caohao */public class JobScheduler &#123; private static final String SCHEDULER_INSTANCE_NAME_SUFFIX = "Scheduler"; private static final String CRON_TRIGGER_IDENTITY_SUFFIX = "Trigger"; //作业启动器 private final JobExecutor jobExecutor; public JobScheduler(final CoordinatorRegistryCenter regCenter, final JobConfiguration jobConfig, final ElasticJobListener... elasticJobListeners) &#123; jobExecutor = new JobExecutor(regCenter, jobConfig, elasticJobListeners); &#125; /** * 初始化作业. */ public void init() &#123; //作业启动器初始化 jobExecutor.init(); //建造者模式构造jobDetail JobDetail jobDetail = JobBuilder.newJob(LiteJob.class).withIdentity(jobExecutor.getJobName()).build(); //保留job的状态信息 jobDetail.getJobDataMap().put("elasticJob", jobExecutor.getElasticJob()); JobScheduleController jobScheduleController; try &#123; //实例化作业调度控制器 jobScheduleController = new JobScheduleController( initializeScheduler(jobDetail.getKey().toString()), jobDetail, jobExecutor.getSchedulerFacade(), Joiner.on("_").join(jobExecutor.getJobName(), CRON_TRIGGER_IDENTITY_SUFFIX)); jobScheduleController.scheduleJob(jobExecutor.getSchedulerFacade().getCron()); &#125; catch (final SchedulerException ex) &#123; throw new JobException(ex); &#125; //向作业注册表注册JobScheduleController实例 JobRegistry.getInstance().addJobScheduleController(jobExecutor.getJobName(), jobScheduleController); &#125; private Scheduler initializeScheduler(final String jobName) throws SchedulerException &#123; //工厂方法构造quartz的Scheduler实例 StdSchedulerFactory factory = new StdSchedulerFactory(); factory.initialize(getBaseQuartzProperties(jobName)); Scheduler result = factory.getScheduler(); //注册Trigger监听事件 result.getListenerManager().addTriggerListener(jobExecutor.getSchedulerFacade().newJobTriggerListener()); return result; &#125; private Properties getBaseQuartzProperties(final String jobName) &#123; Properties result = new Properties(); result.put("org.quartz.threadPool.class", org.quartz.simpl.SimpleThreadPool.class.getName()); //并发执行线程数为1，意味着job任务同步执行，防止同一个任务执行时间过长被多次执行 result.put("org.quartz.threadPool.threadCount", "1"); result.put("org.quartz.scheduler.instanceName", Joiner.on("_").join(jobName, SCHEDULER_INSTANCE_NAME_SUFFIX)); if (!jobExecutor.getSchedulerFacade().isMisfire()) &#123; result.put("org.quartz.jobStore.misfireThreshold", "1"); &#125; prepareEnvironments(result); return result; &#125; //钩子方法，用于子类覆盖 protected void prepareEnvironments(final Properties props) &#123; &#125; &#125;作业启动器的init方法1234567891011121314151617181920212223242526272829303132333435363738/** * JobExecutor * 初始化作业. */ public void init() &#123; log.debug("Elastic job: job controller init, job name is: &#123;&#125;.", jobName); //清除上次secheduler的信息 schedulerFacade.clearPreviousServerStatus(); //向注册中心注册当前job regCenter.addCacheData("/" + jobName); //门面类执行具体业务初始化工作 schedulerFacade.registerStartUpInfo(); &#125; /** * SchedulerFacade门面类 * 注册Elastic-Job启动信息. */ public void registerStartUpInfo() &#123; //启动所有监听事件 listenerManager.startAllListeners(); //强制主节点选举 leaderElectionService.leaderForceElection(); //持久化分布式作业配置信息 configService.persistJobConfiguration(); //持久化作业服务器上线相关信息 serverService.persistServerOnline(); //清除暂停作业的标记 serverService.clearJobPausedStatus(); if (JobType.DATA_FLOW == configService.getJobType()) &#123; //异步开启定时批量统计处理数据数量的作业 statisticsService.startProcessCountJob(); &#125; //设置需要重新分片的标记 shardingService.setReshardingFlag(); //初始化作业监听服务 monitorService.listen(); &#125;作业注册表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 作业注册表. * * @author zhangliang * @author caohao *///多线程双检锁：保证单例线程安全@NoArgsConstructor(access = AccessLevel.PRIVATE)public final class JobRegistry &#123; //为什么要用volatile关键字？ private static volatile JobRegistry instance; //全局的作业被以map形式缓存在注册表单例中 private Map&lt;String, JobScheduleController&gt; schedulerMap = new ConcurrentHashMap&lt;&gt;(); /** * 获取作业注册表实例. * * @return 作业注册表实例 */ public static JobRegistry getInstance() &#123; if (null == instance) &#123; synchronized (JobRegistry.class) &#123; if (null == instance) &#123; //实际上实例化分为分配内存和执行构造方法两部分，如果不加volatile，会导致指令重排序，导致构造方法先被执行。 //而另一个线程到达临界区代码段，从而获取到一个未被完全实例化的instance。 instance = new JobRegistry(); &#125; &#125; &#125; return instance; &#125; /** * 添加作业调度控制器. * * @param jobName 作业名称 * @param jobScheduleController 作业调度控制器 */ public void addJobScheduleController(final String jobName, final JobScheduleController jobScheduleController) &#123; schedulerMap.put(jobName, jobScheduleController); &#125; /** * 获取作业调度控制器. * * @param jobName 作业名称 * @return 作业调度控制器 */ public JobScheduleController getJobScheduleController(final String jobName) &#123; return schedulerMap.get(jobName); &#125;&#125;JobExecutor作业启动器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 作业启动器. * * @author zhangliang */@Slf4j@Getterpublic class JobExecutor &#123; private final String jobName; //分布式注册中心 private final CoordinatorRegistryCenter regCenter; //作业具体执行器 private final ElasticJob elasticJob; //为调度器提供内部服务的门面类 private final SchedulerFacade schedulerFacade; /** * 初始化作业. */ public void init() &#123; log.debug("Elastic job: job controller init, job name is: &#123;&#125;.", jobName); //清楚上次作业状态信息 schedulerFacade.clearPreviousServerStatus(); //向注册中心注册当前任务 regCenter.addCacheData("/" + jobName); //注册Elastic-Job启动信息 schedulerFacade.registerStartUpInfo(); &#125; public JobExecutor(final CoordinatorRegistryCenter regCenter, final JobConfiguration jobConfig, final ElasticJobListener... elasticJobListeners) &#123; jobName = jobConfig.getJobName(); this.regCenter = regCenter; List&lt;ElasticJobListener&gt; elasticJobListenerList = Arrays.asList(elasticJobListeners); setGuaranteeServiceForElasticJobListeners(regCenter, jobConfig, elasticJobListenerList); elasticJob = createElasticJob(jobConfig, elasticJobListenerList); schedulerFacade = new SchedulerFacade(regCenter, jobConfig, elasticJobListenerList); &#125; private void setGuaranteeServiceForElasticJobListeners(final CoordinatorRegistryCenter regCenter, final JobConfiguration jobConfig, final List&lt;ElasticJobListener&gt; elasticJobListeners) &#123; GuaranteeService guaranteeService = new GuaranteeService(regCenter, jobConfig); for (ElasticJobListener each : elasticJobListeners) &#123; if (each instanceof AbstractDistributeOnceElasticJobListener) &#123; ((AbstractDistributeOnceElasticJobListener) each).setGuaranteeService(guaranteeService); &#125; &#125; &#125; private ElasticJob createElasticJob(final JobConfiguration jobConfig, final List&lt;ElasticJobListener&gt; elasticJobListenerList) &#123; ElasticJob result; try &#123; result = (ElasticJob) jobConfig.getJobClass().newInstance(); &#125; catch (final InstantiationException | IllegalAccessException ex) &#123; throw new JobException(ex); &#125; result.setJobFacade(new JobFacade(regCenter, jobConfig, elasticJobListenerList)); return result; &#125;&#125;注册中心模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Override public void init() &#123; //如果开关开启，则启动zk内部服务器，提供job节点注册服务 if (zkConfig.isUseNestedZookeeper()) &#123; NestedZookeeperServers.getInstance().startServerIfNotStarted(zkConfig.getNestedPort(), zkConfig.getNestedDataDir()); &#125; log.debug("Elastic job: zookeeper registry center init, server lists is: &#123;&#125;.", zkConfig.getServerLists()); //创建zk连接客户端 Builder builder = CuratorFrameworkFactory.builder() .connectString(zkConfig.getServerLists()) .retryPolicy(new ExponentialBackoffRetry( zkConfig.getBaseSleepTimeMilliseconds(), zkConfig.getMaxRetries(), zkConfig.getMaxSleepTimeMilliseconds())) .namespace(zkConfig.getNamespace()); if (0 != zkConfig.getSessionTimeoutMilliseconds()) &#123; builder.sessionTimeoutMs(zkConfig.getSessionTimeoutMilliseconds()); &#125; if (0 != zkConfig.getConnectionTimeoutMilliseconds()) &#123; builder.connectionTimeoutMs(zkConfig.getConnectionTimeoutMilliseconds()); &#125; //根据配置，开启权限验证 if (!Strings.isNullOrEmpty(zkConfig.getDigest())) &#123; builder.authorization("digest", zkConfig.getDigest().getBytes(Charset.forName("UTF-8"))) .aclProvider(new ACLProvider() &#123; @Override public List&lt;ACL&gt; getDefaultAcl() &#123; return ZooDefs.Ids.CREATOR_ALL_ACL; &#125; @Override public List&lt;ACL&gt; getAclForPath(final String path) &#123; return ZooDefs.Ids.CREATOR_ALL_ACL; &#125; &#125;); &#125; client = builder.build(); client.start(); try &#123; //客户端锁定并尝试连接注册中心 client.blockUntilConnected(zkConfig.getMaxSleepTimeMilliseconds() * zkConfig.getMaxRetries(), TimeUnit.MILLISECONDS); if (!client.getZookeeperClient().isConnected()) &#123; throw new KeeperException.OperationTimeoutException(); &#125; if (!Strings.isNullOrEmpty(zkConfig.getLocalPropertiesPath())) &#123; //根据路径读取配置文件，并创建节点 fillData(); &#125; //CHECKSTYLE:OFF &#125; catch (final Exception ex) &#123; //CHECKSTYLE:ON RegExceptionHandler.handleException(ex); &#125; &#125;plugin模块中的三种作业类型elastic-job提供了三种类型的作业：Simple类型作业、Dataflow类型作业、Script类型作业。这里主要讲解前两者。Script类型作业意为脚本类型作业，支持shell，python，perl等所有类型脚本，使用不多，可以参见github文档。SimpleJob需要实现SimpleJob接口，意为简单实现，未经过任何封装，与quartz原生接口相似，比如示例代码中所使用的job。12345678910111213141516171819202122232425/** * 简单的分布式作业. * * &lt;p&gt; * 仅保证作业可被分布式定时调用, 不提供任何作业处理逻辑. * &lt;/p&gt; * * @author zhangliang * @author caohao */@Slf4jpublic abstract class AbstractSimpleElasticJob extends AbstractElasticJob &#123; @Override protected final void executeJob(final JobExecutionMultipleShardingContext shardingContext) &#123; process(shardingContext); &#125; /** * 执行作业. * * @param shardingContext 作业分片规则配置上下文 */ public abstract void process(final JobExecutionMultipleShardingContext shardingContext);&#125;Dataflow类型用于处理数据流，需实现DataflowJob接口。该接口提供2个方法可供覆盖，分别用于抓取(fetchData)和处理(processData)数据。可通过DataflowJobConfiguration配置是否流式处理。流式处理数据只有fetchData方法的返回值为null或集合长度为空时，作业才停止抓取，否则作业将一直运行下去； 非流式处理数据则只会在每次作业执行过程中执行一次fetchData方法和processData方法，随即完成本次作业。实际开发中，Dataflow类型的job还是很有好用的。12345678910111213141516171819202122232425262728293031323334353637383940/** * 保证同一分片顺序性的批量处理数据流程的作业. * * @author zhangliang * * @param &lt;T&gt; 数据流作业处理的数据实体类型 */public abstract class AbstractBatchSequenceDataFlowElasticJob&lt;T&gt; extends AbstractBatchDataFlowElasticJob&lt;T, JobExecutionSingleShardingContext&gt; &#123;&#125;/** * 高吞吐量批量处理数据流程的作业. * * @author zhangliang * * @param &lt;T&gt; 数据流作业处理的数据实体类型 */public abstract class AbstractBatchThroughputDataFlowElasticJob&lt;T&gt; extends AbstractBatchDataFlowElasticJob&lt;T, JobExecutionMultipleShardingContext&gt; &#123;&#125;/** * 保证同一分片顺序性的逐条处理数据流程的作业. * * @author zhangliang * * @param &lt;T&gt; 数据流作业处理的数据实体类型 */public abstract class AbstractIndividualSequenceDataFlowElasticJob&lt;T&gt; extends AbstractIndividualDataFlowElasticJob&lt;T, JobExecutionSingleShardingContext&gt; &#123;&#125;/** * 高吞吐量逐条处理数据流程的作业. * * @author zhangliang * * @param &lt;T&gt; 数据流作业处理的数据实体类型 */public abstract class AbstractIndividualThroughputDataFlowElasticJob&lt;T&gt; extends AbstractIndividualDataFlowElasticJob&lt;T, JobExecutionMultipleShardingContext&gt; &#123;&#125;plugin中的分片策略AverageAllocationJobShardingStrategy：基于平均分配算法的分片策略；OdevitySortByNameJobShardingStrategy：根据作业名的哈希值奇偶数决定IP升降序算法的分片策略；RotateServerByNameJobShardingStrategy：根据作业名的哈希值对服务器列表进行轮转的分片策略；12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 基于平均分配算法的分片策略. * * &lt;p&gt; * 如果分片不能整除, 则不能整除的多余分片将依次追加到序号小的服务器. * 如: * 1. 如果有3台服务器, 分成9片, 则每台服务器分到的分片是: 1=[0,1,2], 2=[3,4,5], 3=[6,7,8]. * 2. 如果有3台服务器, 分成8片, 则每台服务器分到的分片是: 1=[0,1,6], 2=[2,3,7], 3=[4,5]. * 3. 如果有3台服务器, 分成10片, 则每台服务器分到的分片是: 1=[0,1,2,9], 2=[3,4,5], 3=[6,7,8]. * &lt;/p&gt; * * @author zhangliang */public final class AverageAllocationJobShardingStrategy implements JobShardingStrategy &#123; @Override public Map&lt;String, List&lt;Integer&gt;&gt; sharding(final List&lt;String&gt; serversList, final JobShardingStrategyOption option) &#123; if (serversList.isEmpty()) &#123; return Collections.emptyMap(); &#125; Map&lt;String, List&lt;Integer&gt;&gt; result = shardingAliquot(serversList, option.getShardingTotalCount()); addAliquant(serversList, option.getShardingTotalCount(), result); return result; &#125; //平均分配前面若干项 private Map&lt;String, List&lt;Integer&gt;&gt; shardingAliquot(final List&lt;String&gt; serversList, final int shardingTotalCount) &#123; Map&lt;String, List&lt;Integer&gt;&gt; result = new LinkedHashMap&lt;&gt;(serversList.size()); int itemCountPerSharding = shardingTotalCount / serversList.size(); int count = 0; for (String each : serversList) &#123; List&lt;Integer&gt; shardingItems = new ArrayList&lt;&gt;(itemCountPerSharding + 1); for (int i = count * itemCountPerSharding; i &lt; (count + 1) * itemCountPerSharding; i++) &#123; shardingItems.add(i); &#125; result.put(each, shardingItems); count++; &#125; return result; &#125; //追加不能整除的分片索引 private void addAliquant(final List&lt;String&gt; serversList, final int shardingTotalCount, final Map&lt;String, List&lt;Integer&gt;&gt; shardingResult) &#123; int aliquant = shardingTotalCount % serversList.size(); int count = 0; for (Entry&lt;String, List&lt;Integer&gt;&gt; entry : shardingResult.entrySet()) &#123; if (count &lt; aliquant) &#123; entry.getValue().add(shardingTotalCount / serversList.size() * serversList.size() + count); &#125; count++; &#125; &#125;&#125;123456789101112131415161718192021222324252627/** * 根据作业名的哈希值奇偶数决定IP升降序算法的分片策略. * * &lt;p&gt; * 作业名的哈希值为奇数则IP升序. * 作业名的哈希值为偶数则IP降序. * 用于不同的作业平均分配负载至不同的服务器. * 如: * 1. 如果有3台服务器, 分成2片, 作业名称的哈希值为奇数, 则每台服务器分到的分片是: 1=[0], 2=[1], 3=[]. * 2. 如果有3台服务器, 分成2片, 作业名称的哈希值为偶数, 则每台服务器分到的分片是: 3=[0], 2=[1], 1=[]. * &lt;/p&gt; * * @author zhangliang */public final class OdevitySortByNameJobShardingStrategy implements JobShardingStrategy &#123; private AverageAllocationJobShardingStrategy averageAllocationJobShardingStrategy = new AverageAllocationJobShardingStrategy(); @Override public Map&lt;String, List&lt;Integer&gt;&gt; sharding(final List&lt;String&gt; serversList, final JobShardingStrategyOption option) &#123; long jobNameHash = option.getJobName().hashCode(); if (0 == jobNameHash % 2) &#123; Collections.reverse(serversList); &#125; return averageAllocationJobShardingStrategy.sharding(serversList, option); &#125;&#125;1234567891011121314151617181920212223242526272829/** * 根据作业名的哈希值对服务器列表进行轮转的分片策略. * 向左偏移offset位之后进行平均分配 * * @author weishubin */public class RotateServerByNameJobShardingStrategy implements JobShardingStrategy &#123; private AverageAllocationJobShardingStrategy averageAllocationJobShardingStrategy = new AverageAllocationJobShardingStrategy(); @Override public Map&lt;String, List&lt;Integer&gt;&gt; sharding(final List&lt;String&gt; serversList, final JobShardingStrategyOption option) &#123; return averageAllocationJobShardingStrategy.sharding(rotateServerList(serversList, option.getJobName()), option); &#125; private List&lt;String&gt; rotateServerList(final List&lt;String&gt; serversList, final String jobName) &#123; int serverSize = serversList.size(); int offset = Math.abs(jobName.hashCode()) % serverSize; if (0 == offset) &#123; return serversList; &#125; List&lt;String&gt; result = new ArrayList&lt;&gt;(serverSize); for (int i = 0; i &lt; serverSize; i++) &#123; int index = (i + offset) % serverSize; result.add(serversList.get(index)); &#125; return result; &#125;&#125;]]></content>
      <tags>
        <tag>elastic-job</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elastic-job源码浅析-任务执行过程]]></title>
    <url>%2F2018%2F10%2F25%2Felastic-job%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90-%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[启动过程流程图流程图详细地描述了各个作业细节的执行过程，看上去流程非常复杂，其主要的功能点为：判断作业是否可执行，判断作业是否分片执行，作业执行状态监听，作业失效转移等。下面我们结合代码一步步窥探他的执行过程。核心源码分析作业入口123456789101112131415/** * Elastic Job Lite提供的Quartz封装作业. * * @author zhangliang */public class LiteJob implements Job &#123; @Setter private ElasticJob elasticJob; @Override public void execute(final JobExecutionContext context) throws JobExecutionException &#123; elasticJob.execute(); &#125;&#125;LiteJob实现了Quartz的Job接口，并且持有elasticJob的实现类，通过代理的方式实现了ElasticJob与Quartz的无缝衔接；【亮点】这是一种典型的代理模式，其好处在于体验上完全与Quartz的Job一致，并且遵循了代码的开闭原则，使得代码具有很好地拓展性：例如ElasticJob接口有SimpleJob，DataFlowJob或者用户自定义的多种实现类，因此具有很好地拓展性。AbstractElasticJob抽象类及其原理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/** * 弹性化分布式作业的基类. * * @author zhangliang * @author caohao */@Slf4jpublic abstract class AbstractElasticJob implements ElasticJob &#123; //具体的业务实现放在jobFacade门面类中实现，简化代码复杂度 private JobFacade jobFacade; @Override public final void execute() &#123; log.trace("Elastic job: job execute begin."); //判断与注册中心时间差是否在允许范围内 jobFacade.checkMaxTimeDiffSecondsTolerable(); //获取分片上下文 JobExecutionMultipleShardingContext shardingContext = jobFacade.getShardingContext(); //若前面的任务仍在执行，则设置错过执行标记，延迟执行 if (jobFacade.misfireIfNecessary(shardingContext.getShardingItems())) &#123; log.debug("Elastic job: previous job is still running, new job will start after previous job completed. Misfired job had recorded."); return; &#125; //清除作业上次执行的信息 jobFacade.cleanPreviousExecutionInfo(); try &#123; //各监听器执行job执行前方法 jobFacade.beforeJobExecuted(shardingContext); //CHECKSTYLE:OFF &#125; catch (final Throwable cause) &#123; //CHECKSTYLE:ON handleJobExecutionException(new JobException(cause)); &#125; //执行具体的job业务逻辑 executeJobInternal(shardingContext); log.trace("Elastic job: execute normal completed, sharding context:&#123;&#125;.", shardingContext); while (jobFacade.isExecuteMisfired(shardingContext.getShardingItems())) &#123; log.trace("Elastic job: execute misfired job, sharding context:&#123;&#125;.", shardingContext); jobFacade.clearMisfire(shardingContext.getShardingItems()); executeJobInternal(shardingContext); log.trace("Elastic job: misfired job completed, sharding context:&#123;&#125;.", shardingContext); &#125; //按需失效转移 jobFacade.failoverIfNecessary(); try &#123; //执行监听后事件 jobFacade.afterJobExecuted(shardingContext); //CHECKSTYLE:OFF &#125; catch (final Throwable cause) &#123; //CHECKSTYLE:ON handleJobExecutionException(new JobException(cause)); &#125; log.trace("Elastic job: execute all completed."); &#125; private void executeJobInternal(final JobExecutionMultipleShardingContext shardingContext) &#123; if (shardingContext.getShardingItems().isEmpty()) &#123; log.trace("Elastic job: sharding item is empty, job execution context:&#123;&#125;.", shardingContext); return; &#125; //注册任务执行信息 jobFacade.registerJobBegin(shardingContext); try &#123; executeJob(shardingContext); //CHECKSTYLE:OFF &#125; catch (final Throwable cause) &#123; //CHECKSTYLE:ON handleJobExecutionException(new JobException(cause)); &#125; finally &#123; // TODO 考虑增加作业失败的状态，并且考虑如何处理作业失败的整体回路 jobFacade.registerJobCompleted(shardingContext); &#125; &#125; protected abstract void executeJob(final JobExecutionMultipleShardingContext shardingContext); @Override public void handleJobExecutionException(final JobException jobException) &#123; log.error("Elastic job: exception occur in job processing...", jobException.getCause()); &#125; @Override public final JobFacade getJobFacade() &#123; return jobFacade; &#125; @Override public final void setJobFacade(final JobFacade jobFacade) &#123; this.jobFacade = jobFacade; &#125;【亮点】外观模式传送门上面的代码中应用到了外观模式（Facade），AbstractElasticJob持有jobFacade对象，Elasticjob负责统筹整体的job执行流程但无需关注业务的具体实现，转而将复杂的业务处理逻辑交由jobFacade中的方法进行处理，从而将job与具体的业务逻辑抽离出来方便阅读和拓展。]]></content>
      <tags>
        <tag>elastic-job</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elastic-job源码浅析-任务初始化]]></title>
    <url>%2F2018%2F10%2F25%2Felastic-job%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90-%E4%BB%BB%E5%8A%A1%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[作业过程源码分析核心入口：JobScheduler作业调度器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 作业调度器. * * @author zhangliang * @author caohao */public class JobScheduler &#123; private static final String SCHEDULER_INSTANCE_NAME_SUFFIX = "Scheduler"; private static final String CRON_TRIGGER_IDENTITY_SUFFIX = "Trigger"; //作业启动器 private final JobExecutor jobExecutor; public JobScheduler(final CoordinatorRegistryCenter regCenter, final JobConfiguration jobConfig, final ElasticJobListener... elasticJobListeners) &#123; jobExecutor = new JobExecutor(regCenter, jobConfig, elasticJobListeners); &#125; /** * 初始化作业. */ public void init() &#123; //作业启动器初始化 jobExecutor.init(); //建造者模式构造jobDetail JobDetail jobDetail = JobBuilder.newJob(LiteJob.class).withIdentity(jobExecutor.getJobName()).build(); //保留job的状态信息 jobDetail.getJobDataMap().put("elasticJob", jobExecutor.getElasticJob()); JobScheduleController jobScheduleController; try &#123; //实例化作业调度控制器 jobScheduleController = new JobScheduleController( initializeScheduler(jobDetail.getKey().toString()), jobDetail, jobExecutor.getSchedulerFacade(), Joiner.on("_").join(jobExecutor.getJobName(), CRON_TRIGGER_IDENTITY_SUFFIX)); jobScheduleController.scheduleJob(jobExecutor.getSchedulerFacade().getCron()); &#125; catch (final SchedulerException ex) &#123; throw new JobException(ex); &#125; //向作业注册表注册JobScheduleController实例 JobRegistry.getInstance().addJobScheduleController(jobExecutor.getJobName(), jobScheduleController); &#125; private Scheduler initializeScheduler(final String jobName) throws SchedulerException &#123; //工厂方法构造quartz的Scheduler实例 StdSchedulerFactory factory = new StdSchedulerFactory(); factory.initialize(getBaseQuartzProperties(jobName)); Scheduler result = factory.getScheduler(); //注册Trigger监听事件 result.getListenerManager().addTriggerListener(jobExecutor.getSchedulerFacade().newJobTriggerListener()); return result; &#125; private Properties getBaseQuartzProperties(final String jobName) &#123; Properties result = new Properties(); result.put("org.quartz.threadPool.class", org.quartz.simpl.SimpleThreadPool.class.getName()); //并发执行线程数为1，意味着job任务同步执行，防止同一个任务执行时间过长被重复执行 result.put("org.quartz.threadPool.threadCount", "1"); result.put("org.quartz.scheduler.instanceName", Joiner.on("_").join(jobName, SCHEDULER_INSTANCE_NAME_SUFFIX)); if (!jobExecutor.getSchedulerFacade().isMisfire()) &#123; result.put("org.quartz.jobStore.misfireThreshold", "1"); &#125; prepareEnvironments(result); return result; &#125; //钩子方法，用于子类覆盖 protected void prepareEnvironments(final Properties props) &#123; &#125; &#125;JobExecutor作业启动器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 作业启动器. * * @author zhangliang */@Slf4j@Getterpublic class JobExecutor &#123; private final String jobName; //分布式注册中心 private final CoordinatorRegistryCenter regCenter; //作业具体执行器 private final ElasticJob elasticJob; //为调度器提供内部服务的门面类 private final SchedulerFacade schedulerFacade; /** * 初始化作业. */ public void init() &#123; log.debug("Elastic job: job controller init, job name is: &#123;&#125;.", jobName); //清楚上次作业状态信息 schedulerFacade.clearPreviousServerStatus(); //向注册中心注册当前任务 regCenter.addCacheData("/" + jobName); //注册Elastic-Job启动信息 schedulerFacade.registerStartUpInfo(); &#125; public JobExecutor(final CoordinatorRegistryCenter regCenter, final JobConfiguration jobConfig, final ElasticJobListener... elasticJobListeners) &#123; jobName = jobConfig.getJobName(); this.regCenter = regCenter; List&lt;ElasticJobListener&gt; elasticJobListenerList = Arrays.asList(elasticJobListeners); setGuaranteeServiceForElasticJobListeners(regCenter, jobConfig, elasticJobListenerList); elasticJob = createElasticJob(jobConfig, elasticJobListenerList); schedulerFacade = new SchedulerFacade(regCenter, jobConfig, elasticJobListenerList); &#125; private void setGuaranteeServiceForElasticJobListeners(final CoordinatorRegistryCenter regCenter, final JobConfiguration jobConfig, final List&lt;ElasticJobListener&gt; elasticJobListeners) &#123; GuaranteeService guaranteeService = new GuaranteeService(regCenter, jobConfig); for (ElasticJobListener each : elasticJobListeners) &#123; if (each instanceof AbstractDistributeOnceElasticJobListener) &#123; ((AbstractDistributeOnceElasticJobListener) each).setGuaranteeService(guaranteeService); &#125; &#125; &#125; private ElasticJob createElasticJob(final JobConfiguration jobConfig, final List&lt;ElasticJobListener&gt; elasticJobListenerList) &#123; ElasticJob result; try &#123; result = (ElasticJob) jobConfig.getJobClass().newInstance(); &#125; catch (final InstantiationException | IllegalAccessException ex) &#123; throw new JobException(ex); &#125; result.setJobFacade(new JobFacade(regCenter, jobConfig, elasticJobListenerList)); return result; &#125;&#125;JobFacade门面类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * 为调度器提供内部服务的门面类. * * @author zhangliang */public class SchedulerFacade &#123; private final ConfigurationService configService; private final LeaderElectionService leaderElectionService; private final ServerService serverService; private final ShardingService shardingService; private final ExecutionService executionService; private final StatisticsService statisticsService; private final MonitorService monitorService; private final ListenerManager listenerManager; public SchedulerFacade(final CoordinatorRegistryCenter coordinatorRegistryCenter, final JobConfiguration jobConfiguration, final List&lt;ElasticJobListener&gt; elasticJobListeners) &#123; configService = new ConfigurationService(coordinatorRegistryCenter, jobConfiguration); leaderElectionService = new LeaderElectionService(coordinatorRegistryCenter, jobConfiguration); serverService = new ServerService(coordinatorRegistryCenter, jobConfiguration); shardingService = new ShardingService(coordinatorRegistryCenter, jobConfiguration); executionService = new ExecutionService(coordinatorRegistryCenter, jobConfiguration); statisticsService = new StatisticsService(coordinatorRegistryCenter, jobConfiguration); monitorService = new MonitorService(coordinatorRegistryCenter, jobConfiguration); listenerManager = new ListenerManager(coordinatorRegistryCenter, jobConfiguration, elasticJobListeners); &#125; /** * 每次作业启动前清理上次运行状态. */ public void clearPreviousServerStatus() &#123; serverService.clearPreviousServerStatus(); &#125; /** * 注册Elastic-Job启动信息. */ public void registerStartUpInfo() &#123; //启动各类监听器 listenerManager.startAllListeners(); //强制选举主节点 leaderElectionService.leaderForceElection(); //zk中持久化分布式作业配置信息 configService.persistJobConfiguration(); //zk中持久化作业服务器上线相关信息. serverService.persistServerOnline(); //清除暂停作业的标记. serverService.clearJobPausedStatus(); if (JobType.DATA_FLOW == configService.getJobType()) &#123; //异步开启统计处理数据数量的作业 statisticsService.startProcessCountJob(); &#125; //设置需要重新分片的标记 shardingService.setReshardingFlag(); //初始化作业监控服务 monitorService.listen(); &#125; /** * 释放作业占用的资源. */ public void releaseJobResource() &#123; monitorService.close(); if (JobType.DATA_FLOW.equals(configService.getJobType())) &#123; statisticsService.stopProcessCountJob(); &#125; serverService.removeServerStatus(); &#125; /** * 获取作业启动时间的cron表达式. * * @return 作业启动时间的cron表达式 */ public String getCron() &#123; return configService.getCron(); &#125; /** * 获取是否开启misfire. * * @return 是否开启misfire */ public boolean isMisfire() &#123; return configService.isMisfire(); &#125; /** * 获取作业触发监听器. * * @return 作业触发监听器 */ public JobTriggerListener newJobTriggerListener() &#123; return new JobTriggerListener(executionService, shardingService); &#125;&#125;作业注册表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 作业注册表. * * @author zhangliang * @author caohao *///多线程双检锁：保证单例线程安全@NoArgsConstructor(access = AccessLevel.PRIVATE)public final class JobRegistry &#123; //为什么要用volatile关键字？ private static volatile JobRegistry instance; //全局的作业被以map形式缓存在注册表单例中 private Map&lt;String, JobScheduleController&gt; schedulerMap = new ConcurrentHashMap&lt;&gt;(); /** * 获取作业注册表实例. * * @return 作业注册表实例 */ public static JobRegistry getInstance() &#123; if (null == instance) &#123; synchronized (JobRegistry.class) &#123; if (null == instance) &#123; //实际上实例化分为分配内存和执行构造方法两部分，如果不加volatile，会导致指令重排序，导致构造方法先被执行。 //而另一个线程到达临界区代码段，从而获取到一个未被完全实例化的instance。 instance = new JobRegistry(); &#125; &#125; &#125; return instance; &#125; /** * 添加作业调度控制器. * * @param jobName 作业名称 * @param jobScheduleController 作业调度控制器 */ public void addJobScheduleController(final String jobName, final JobScheduleController jobScheduleController) &#123; schedulerMap.put(jobName, jobScheduleController); &#125; /** * 获取作业调度控制器. * * @param jobName 作业名称 * @return 作业调度控制器 */ public JobScheduleController getJobScheduleController(final String jobName) &#123; return schedulerMap.get(jobName); &#125;&#125;]]></content>
      <tags>
        <tag>elastic-job</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elastic-job源码浅析-架构篇]]></title>
    <url>%2F2018%2F10%2F25%2Felastic-job%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90-%E6%9E%B6%E6%9E%84%E7%AF%87%2F</url>
    <content type="text"><![CDATA[源码阅读小技巧传送门写在前面elastic-job是当当开源的一款非常好用的作业框架，在此之前，任务调度的主流框架是quartZ或者spring-task。两者均不能很好地支持高并发量的分布式任务调度，即使是号称拥有集群能力的quartZ也仅仅保证了job的高可用，单一时刻只能有一台机器执行具体的调度任务。因此，老牌劲旅无法解决两个迫切的需求点：1.quartZ的集群仅仅是用于实现HA（high avalible),无法实现高并发；2.无论quartZ还是spring-task，均无法很好地实现水平拓展；1Elastic-Job is a distributed scheduled job framework, based on Quartz and Zookeeper.上述文字是elastic-job github主页对它的描述，从上面的描述中我们可以看到两个关键字Quartz和Zookeeper，基于以上两个基础框架，Elastic-job实现了高可用和高并发。elastic-job解决了那些问题举个典型的job场景，比如余额宝里的昨日收益，系统需要job在每天某个时间点开始，给所有余额宝用户计算收益。如果用户数量不多，我们可以轻易使用quartz来完成，我们让计息job在某个时间点开始执行，循环遍历所有用户计算利息，这没问题。可是，如果用户体量特别大，我们可能会面临着在第二天之前处理不完这么多用户。另外，我们部署job的时候也得注意，我们可能会把job直接放在我们的webapp里，webapp通常是多节点部署的，这样，我们的job也就是多节点，多个job同时执行，很容易造成重复执行，比如用户重复计息，为了避免这种情况，我们可能会对job的执行加锁，保证始终只有一个节点能执行，或者干脆让job从webapp里剥离出来，独自部署一个节点。elastic-job就可以帮助我们解决上面的问题，elastic底层的任务调度还是使用的quartz，通过zookeeper来动态给job节点分片。我们来看：很大体量的用户需要在特定的时间段内计息完成我们肯定是希望我们的任务可以通过集群达到水平扩展，集群里的每个节点都处理部分用户，不管用户数量有多庞大，我们只要增加机器就可以了，比如单台机器特定时间能处理n个用户，2台机器处理2n个用户，3台3n，4台4n…，再多的用户也不怕了。使用elastic-job开发的作业都是zookeeper的客户端，比如我希望3台机器跑job，我们将任务分成3片，框架通过zk的协调，最终会让3台机器分别分配到0,1,2的任务片，比如server0–&gt;0，server1–&gt;1，server2–&gt;2，当server0执行时，可以只查询id%3==0的用户，server1执行时，只查询id%3==1的用户，server2执行时，只查询id%3==2的用户。任务部署多节点引发重复执行在上面的基础上，我们再增加server3，此时，server3分不到任务分片，因为只有3片，已经分完了。没有分到任务分片的作业程序将不执行。如果此时server2挂了，那么server2的分片项会分配给server3，server3有了分片，就会替代server2执行。如果此时server3也挂了，只剩下server0和server1了，框架也会自动把server3的分片随机分配给server0或者server1，可能会这样，server0–&gt;0，server1–&gt;1,2。这种特性称之为弹性扩容，即elastic-job名称的由来。上述的引用比较冗长，简单地理解就是elastic-job利用zk的分布式集群管理能力，对job节点进行的弹性扩容和收缩。同时任务分片的方式保证了job执行的并发能力和防止重复执行，使任务调度不仅拥有高可用，也具备了水平拓展和高并发能力。elastic-job结构elastic-job架构图任务节点数据结构elastic-job模块简析core的主要的模块分为:job模块：plugin(内含三种不同的作业类型,分片策略)，api(对外暴露的api服务)，exception(异常类)，internal(内部模块)reg(注册中心)模块：base(基类)，异常处理模块，zookeeper注册中心模块]]></content>
      <tags>
        <tag>elastic-job</tag>
        <tag>源码</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo优化攻略]]></title>
    <url>%2F2018%2F10%2F25%2Fhexo%E4%BC%98%E5%8C%96%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[写在前面这个攻略主要是给有一定diy能力的hexo博主。一些细节的攻略可以参考如下文章：hexo 基础配置优化插件进阶静态代码压缩文章比较长的情况下网页往往会显示地较慢。因此，需要对静态代码进行压缩，以提高网站的响应速度。1npm install hexo-all-minifier --save在hexo根目录下的_config.yml中配置:12345678910111213141516171819202122232425262728# 代码压缩 github.com/chenzhutian/hexo-all-minifierall_minifier: truehtml_minifier: enable: true ignore_error: false exclude: css_minifier: enable: true exclude: - '*.min.css'js_minifier: enable: true mangle: true output: compress: exclude: - '*.min.js'image_minifier: enable: false # 图片不压缩 interlaced: false multipass: false optimizationLevel: 2 pngquant: false progressive: false文章加密插件安装1npm install hexo-encrypt --save在项目_config.yml中声名默认密码123#该密码为全局默认密码encrypt: password: 你的密码在文章头加入密码配置12encrypt: trueenc_pwd: 你的文章独立密码在根目录的package.json中追加配置，记得补全“,”1"hexo-encrypt": "^0.2.0"最终效果网站顶部进度条在{hexo-path}/themes/next/layout/_partials/head/head.swig中顶部加入如下代码123456789101112131415&lt;script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"&gt;&lt;/script&gt;&lt;link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"&gt;&lt;style&gt;.pace .pace-progress &#123; background: #f6a427; /*进度条颜色*/ height: 3px;&#125;.pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/&#125;.pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/&#125;&lt;/style&gt;效果图]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>优化</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于装修的一点想法]]></title>
    <url>%2F2018%2F10%2F25%2F%E5%85%B3%E4%BA%8E%E8%A3%85%E4%BF%AE%E7%9A%84%E4%B8%80%E7%82%B9%E6%83%B3%E6%B3%95%2F</url>
    <content type="text"><![CDATA[装修风格的讨论在这个宅基地很难批准的时候，终于可以造房子了。楼房的样式是那种两层平层 + 一层别墅式的样子，虽然比不上欧式的新颖，但是空间足够大，四平八稳的风格还算能接受。对于装修风格，和瓢羹同学也有一些讨论。一开始瓢羹同学认为欧式的辉煌装修风格不错，但是我觉得有点老土。于是呢，她说北欧性冷风不错，我也觉得可以，只是美中不足的是有点暗色调，不适合居家。我呢，有点青睐于和风的风格，比较的小资。但是，作为自建房格调又显得有点小气了。所以，经过一番博弈，我们最终把两种风格进行了mix——其实我们不是一定青睐和风，亦或是北欧。后来我们发现，我们只是对原木风比较感冒。原木材质的纹理，配合较大空间的色彩搭配，整体给人一种居家的舒适感和归属感。同时，又比较有格调。要准备的工作从目前来看打的轮廓和格局已经敲定了，但是整体装修的渲染还没出来，准备抽空到酷家乐搞一波装修效果图。到时候看看整体下来的装修效果如何。装修资料酷家乐 有好几套比较合理的和风装修来自酷家乐，吊顶采用了比较简约的纯白+造型别致的灯具，这个风格我们都比较喜欢。易盖房 小别墅一些样式比较讨巧，看着比较舒服。]]></content>
      <tags>
        <tag>酷玩</tag>
        <tag>装修</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员养生秘笈]]></title>
    <url>%2F2018%2F10%2F21%2F%E7%A8%8B%E5%BA%8F%E7%8C%BF%E5%85%BB%E7%94%9F%2F</url>
    <content type="text"><![CDATA[function doDecrypt (pwd, onError) { console.log('in doDecrypt'); const txt = document.getElementById('enc_content').innerHTML; let plantext; try { const bytes = CryptoJS.AES.decrypt(txt, pwd); var plaintext = bytes.toString(CryptoJS.enc.Utf8); } catch(err) { if(onError) { onError(err); } return; } document.getElementById('enc_content').innerHTML = plaintext; document.getElementById('enc_content').style.display = 'block'; document.getElementById('enc_passwd').style.display = 'none'; if(typeof MathJax !== 'undefined') { MathJax.Hub.Queue( ['resetEquationNumbers', MathJax.InputJax.TeX], ['PreProcess', MathJax.Hub], ['Reprocess', MathJax.Hub] ); } } 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 var onError = function(error) { document.getElementById("enc_error").innerHTML = "password error!" }; function decrypt() { var passwd = document.getElementById("enc_pwd_input").value; console.log(passwd); doDecrypt(passwd, onError); }]]></content>
      <tags>
        <tag>程序员</tag>
        <tag>养生</tag>
        <tag>码农</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 源码阅读]]></title>
    <url>%2F2018%2F10%2F19%2Fspring%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[对于spring源码的一些个人的见解！！！spring 核心代码12345参考资料：spring源码深度解析Spring版本：Spring-4.3.5-RELEASE吐槽下，老外写的东西真晕啊，像亲妈一样啰啰嗦嗦帮你考虑了各种情况，然后最好还不忘加一句：如果你不满意，还可以拓展！！！核心流程初始化过程非常清晰的模板方法，每一个步骤封装成一个具体的函数进行代理，职责清晰明了；12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; //预热，做准备工作 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. //获取内部的bean factory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. //预热beanFactory prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. //beanFactory在上下文中注册bean，核心的代码就在这里 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // bean创建的时候拦截并注册bean处理器，这里只创建处理器，真正的创建是在getBean(..)方法里 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 用于支持国际化，比如一些日志的国际化匹配等； initMessageSource(); // 为上下文初始化消息传播工具 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. // 钩子方法：额外的beans处理方法 onRefresh(); // Check for listener beans and register them. // 注册监听器 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 实例化非延时加载的bean单例 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. // push beans创建完成的消息 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125;spring 类加载的基本类spring DefaultListableBeanFactory UML示意图：spring bean 创建过程转换beanName尝试从缓存中获取单例bean本身的实例化原型模式依赖检测parentBeanFactory 检测将gernerecBeanDefinition 转换成 RootBeanDefination寻找依赖根据scope 初始化(init)对应的bean类型转换123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171/** * Return an instance, which may be shared or independent, of the specified bean. * @param name the name of the bean to retrieve * @param requiredType the required type of the bean to retrieve * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @param typeCheckOnly whether the instance is obtained for a type check, * not for actual use * @return an instance of the bean * @throws BeansException if the bean could not be created */@SuppressWarnings("unchecked")protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; //转换beanName，我们知道在spring中，bean factory的名称都是类似于 &amp;org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory //因此获取的时候需要进行转换 final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. // 尝试从缓存中获取单例 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; //实例化 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // Fail if we're already creating this bean instance: // We're assumably within a circular reference. // 检测当前依赖的类是否正在创建，如果是，则抛出异常 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. // 如果bean配置不存在则只能去父工厂找 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; //转换并合并BeanDefinition属性 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. // 原型模式的bean需要循环检测依赖 防止出现A-&gt;B-&gt;A 的循环依赖情况出现 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; registerDependentBean(dep, beanName); getBean(dep); &#125; &#125; // Create bean instance. // 创建bean实例 if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider " + "defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // Check if required type matches the type of the actual bean instance. // 转换bean类型 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123; try &#123; return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean;&#125;spring事务隔离级别及事务传播实现propagation_requierd(spring的事务默认是该级别)：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是最常见的选择。propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。propagation_required_new：新建事务，如果当前存在事务，把当前事务挂起。propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/** * Create a TransactionStatus for an existing transaction. */private TransactionStatus handleExistingTransaction( TransactionDefinition definition, Object transaction, boolean debugEnabled) throws TransactionException &#123; //若为非事务方式，则抛异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) &#123; throw new IllegalTransactionStateException( "Existing transaction found for transaction marked with propagation 'never'"); &#125; // 若存在事务，挂起适当前事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) &#123; if (debugEnabled) &#123; logger.debug("Suspending current transaction"); &#125; // 挂起当前事务 Object suspendedResources = suspend(transaction); boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); return prepareTransactionStatus( definition, null, false, newSynchronization, debugEnabled, suspendedResources); &#125; // 挂起当前事务，并新建事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) &#123; if (debugEnabled) &#123; logger.debug("Suspending current transaction, creating new transaction with name [" + definition.getName() + "]"); &#125; //挂起当前事务 SuspendedResourcesHolder suspendedResources = suspend(transaction); try &#123; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus( definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); // 重新开启事务 doBegin(transaction, definition); prepareSynchronization(status, definition); return status; &#125; catch (RuntimeException beginEx) &#123; resumeAfterBeginException(transaction, suspendedResources, beginEx); throw beginEx; &#125; catch (Error beginErr) &#123; resumeAfterBeginException(transaction, suspendedResources, beginErr); throw beginErr; &#125; &#125; // 若当前事务存在，则嵌套执行事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; if (!isNestedTransactionAllowed()) &#123; throw new NestedTransactionNotSupportedException( "Transaction manager does not allow nested transactions by default - " + "specify 'nestedTransactionAllowed' property with value 'true'"); &#125; if (debugEnabled) &#123; logger.debug("Creating nested transaction with name [" + definition.getName() + "]"); &#125; // 判定是否支持事务备份点 if (useSavepointForNestedTransaction()) &#123; // Create savepoint within existing Spring-managed transaction, // through the SavepointManager API implemented by TransactionStatus. // Usually uses JDBC 3.0 savepoints. Never activates Spring synchronization. DefaultTransactionStatus status = prepareTransactionStatus(definition, transaction, false, false, debugEnabled, null); // 创建备份点 status.createAndHoldSavepoint(); return status; &#125; else &#123; // Nested transaction through nested begin and commit/rollback calls. // Usually only for JTA: Spring synchronization might get activated here // in case of a pre-existing JTA transaction. boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus( definition, transaction, true, newSynchronization, debugEnabled, null); // 不支持备份点的情况下会新建事务 doBegin(transaction, definition); prepareSynchronization(status, definition); return status; &#125; &#125; // Assumably PROPAGATION_SUPPORTS or PROPAGATION_REQUIRED. if (debugEnabled) &#123; logger.debug("Participating in existing transaction"); &#125; if (isValidateExistingTransaction()) &#123; if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) &#123; Integer currentIsolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel(); if (currentIsolationLevel == null || currentIsolationLevel != definition.getIsolationLevel()) &#123; Constants isoConstants = DefaultTransactionDefinition.constants; throw new IllegalTransactionStateException("Participating transaction with definition [" + definition + "] specifies isolation level which is incompatible with existing transaction: " + (currentIsolationLevel != null ? isoConstants.toCode(currentIsolationLevel, DefaultTransactionDefinition.PREFIX_ISOLATION) : "(unknown)")); &#125; &#125; if (!definition.isReadOnly()) &#123; if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) &#123; throw new IllegalTransactionStateException("Participating transaction with definition [" + definition + "] is not marked as read-only but existing transaction is"); &#125; &#125; &#125; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); return prepareTransactionStatus(definition, transaction, false, newSynchronization, debugEnabled, null);&#125;一些干货aop注入的实现过程doCreateBean中会暴露一个bean引用，用以处理循环引用；同时大家熟知的AOP就是通过getEarlyBeanReference(..)方法植入的；具体的，是在wrapIfNecessary(..) 方法中封装了advice并创建了代理；@Autowired注解的实现doCreateBean(..)中的populateBean(..)方法，实现了基于@Autowired注解的实现，根据名称或类型进行依赖的注入；]]></content>
      <tags>
        <tag>Spring</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Mvc源码阅读]]></title>
    <url>%2F2018%2F10%2F19%2Fspringmvc%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[对springMVC的一些思考!!!Spring Mvc源码阅读12345678910111213SpringMVC核心处理流程：1、DispatcherServlet前端控制器接收发过来的请求，交给HandlerMapping处理器映射器2、HandlerMapping处理器映射器，根据请求路径找到相应的HandlerAdapter处理器适配器（处理器适配器就是那些拦截器或Controller）3、HandlerAdapter处理器适配器，请求数据绑定和转换，处理一些功能请求，返回一个ModelAndView对象（包括模型数据、逻辑视图名）4、ViewResolver视图解析器，先根据ModelAndView中设置的View解析具体视图5、然后再将Model模型中的数据渲染到View上这些过程都是以DispatcherServlet为中轴线进行的。入口源码springMVC的请求会交由dispatcherServlet处理，其本质上是一个多线程的请求处理机制；核心业务逻辑被设计在doDispatcher(..)方法中；123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * Process the actual dispatching to the handler. * &lt;p&gt;The handler will be obtained by applying the servlet's HandlerMappings in order. * The HandlerAdapter will be obtained by querying the servlet's installed HandlerAdapters * to find the first that supports the handler class. * &lt;p&gt;All HTTP methods are handled by this method. It's up to HandlerAdapters or handlers * themselves to decide which methods are acceptable. * @param request current HTTP request * @param response current HTTP response * @throws Exception in case of any kind of processing failure */protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // 绑定url -&gt; 具体的handler/Controller.method(..) // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // 根据handler绑定具体的adapter // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = "GET".equals(method); if (isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug("Last-Modified value for [" + getRequestUri(request) + "] is: " + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // interceptor 拦截器进行前置预处理 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 在handle方法中进行了请求数据的绑定，方法invoke，返回model的处理和封装等 // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException("Handler dispatch failed", err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException("Handler processing failed", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125;核心关注的几个问题请求如何路由到具体的Controller上的方法进行处理?根据请求路径，与已知的handlerMapping进行匹配，并加入interceptors:dispatcherServlet.getHandler()最终调用AbstracteHandlerMapping.getHandlerExecutionChain(..)中进行url与handlerMapping进行匹配，并加入interceptors;扁平化的前端请求数据如何进行数据绑定？我们知道，前端的get/post等请求，会被requestServlet接受，并封装成HttpServletRequest的parameterMap中，每一项请求的数据结构都是 K-V 形的。而我们知道，像这样的形式，那么在这个中间数据如何实现数据绑定到Bean，String格式的Value 转换成各种目标格式。事实上，spring MVC将整个网络请求的处理流程进行了合理的切分,其大致的处理流程如下：12345678910111.调用匹配到的adapter.handle(..)2.然后调用invokeAndHandle(..)3.调用invokeForRequest(..)获取getMethodArgumentValues(..)获取和绑定入参;4.在具体的方法中，获取支持处理的argumentResolvers,然后调用resolveArgument(..)方法;5.在ModelAttributeMethodProcessor中调用bindRequestParameters(binder, webRequest),方法，然后再调用bind()进行bean参数的绑定；6.调用binder.convertIfNecessary(arg, parameter.getParameterType(), parameter)方法进行参数的转换；]]></content>
      <tags>
        <tag>Spring MVC</tag>
        <tag>Spring</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
</search>
